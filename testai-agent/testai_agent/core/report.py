"""
TestAI Agent - Executive Report Generator

Generates professional, executive-ready reports in various formats:
- Markdown (for GitHub/documentation)
- HTML (for email/web)
- Plain text (for terminal)

Reports include:
- Executive Summary
- Risk Assessment Matrix
- Test Coverage Analysis
- Detailed Test Cases
- Recommendations
"""

from typing import List, Dict, Any, Optional
from datetime import datetime
from dataclasses import dataclass


@dataclass
class ExecutiveSummary:
    """Executive summary of the test plan."""
    feature: str
    overall_risk: str
    test_count: int
    critical_tests: int
    high_tests: int
    key_findings: List[str]
    recommendations: List[str]
    estimated_effort: str
    confidence_level: str


class ReportGenerator:
    """
    Generates professional reports from test plans.
    
    Designed for executive audiences who need:
    - Quick overview (can read in 30 seconds)
    - Risk-focused perspective
    - Actionable recommendations
    - Professional presentation
    """
    
    @classmethod
    def generate_executive_summary(
        cls, 
        test_plan, 
        knowledge_confidence: float
    ) -> ExecutiveSummary:
        """Generate an executive summary from a test plan."""
        
        # Count by risk level
        critical = sum(1 for tc in test_plan.test_cases if tc.risk_level.value == "Critical")
        high = sum(1 for tc in test_plan.test_cases if tc.risk_level.value == "High")
        medium = sum(1 for tc in test_plan.test_cases if tc.risk_level.value == "Medium")
        
        # Generate key findings
        findings = []
        if critical > 0:
            findings.append(f"{critical} critical security vulnerabilities identified")
        if high > 0:
            findings.append(f"{high} high-risk scenarios require immediate attention")
        if "Security" in test_plan.by_category:
            findings.append(f"Security testing covers {test_plan.by_category['Security']} scenarios")
        if test_plan.risk_assessment.security_risks:
            findings.append(f"Primary security concern: {test_plan.risk_assessment.security_risks[0]}")
            
        # Generate recommendations
        recommendations = []
        if critical > 0:
            recommendations.append("Prioritize critical security tests before deployment")
        if test_plan.risk_assessment.overall_risk.value in ["Critical", "High"]:
            recommendations.append("Consider security review by dedicated team")
        recommendations.append("Execute full test suite in staging environment first")
        recommendations.extend(test_plan.risk_assessment.recommendations[:2])
        
        # Estimate effort
        effort = cls._estimate_effort(test_plan.total_tests, critical, high)
        
        # Confidence level
        if knowledge_confidence >= 0.7:
            confidence = "High"
        elif knowledge_confidence >= 0.4:
            confidence = "Medium"
        else:
            confidence = "Low - Additional expertise recommended"
            
        return ExecutiveSummary(
            feature=test_plan.feature,
            overall_risk=test_plan.risk_assessment.overall_risk.value,
            test_count=test_plan.total_tests,
            critical_tests=critical,
            high_tests=high,
            key_findings=findings,
            recommendations=recommendations,
            estimated_effort=effort,
            confidence_level=confidence,
        )
    
    @classmethod
    def _estimate_effort(cls, total_tests: int, critical: int, high: int) -> str:
        """Estimate testing effort."""
        # Simple heuristic: critical tests take longer
        hours = total_tests * 0.5 + critical * 2 + high * 1
        
        if hours <= 4:
            return "4-8 hours (1 day)"
        elif hours <= 16:
            return "2-3 days"
        elif hours <= 40:
            return "1 week"
        else:
            return "1-2 weeks"
    
    @classmethod
    def to_markdown(cls, test_plan, executive_summary: ExecutiveSummary) -> str:
        """Generate a full markdown report."""
        
        lines = [
            f"# QA Test Plan Report",
            f"**Feature:** {test_plan.feature}",
            f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"**Generated by:** TestAI Agent (Senior QA Consultant)",
            "",
            "---",
            "",
            "## Executive Summary",
            "",
            f"| Metric | Value |",
            f"|--------|-------|",
            f"| Overall Risk | **{executive_summary.overall_risk}** |",
            f"| Total Test Cases | {executive_summary.test_count} |",
            f"| Critical Tests | {executive_summary.critical_tests} |",
            f"| High Priority Tests | {executive_summary.high_tests} |",
            f"| Estimated Effort | {executive_summary.estimated_effort} |",
            f"| Confidence Level | {executive_summary.confidence_level} |",
            "",
            "### Key Findings",
            "",
        ]
        
        for finding in executive_summary.key_findings:
            lines.append(f"- âš ï¸ {finding}")
            
        lines.extend([
            "",
            "### Recommendations",
            "",
        ])
        
        for i, rec in enumerate(executive_summary.recommendations, 1):
            lines.append(f"{i}. {rec}")
            
        lines.extend([
            "",
            "---",
            "",
            "## Risk Assessment Matrix",
            "",
            "| Risk Area | Level | Details |",
            "|-----------|-------|---------|",
        ])
        
        # Add risk areas
        for risk in test_plan.risk_assessment.security_risks[:3]:
            lines.append(f"| Security | High | {risk} |")
        for risk in test_plan.risk_assessment.functional_risks[:2]:
            lines.append(f"| Functional | Medium | {risk} |")
        for risk in test_plan.risk_assessment.ui_risks[:2]:
            lines.append(f"| UI/UX | Medium | {risk} |")
            
        lines.extend([
            "",
            "---",
            "",
            "## Test Coverage by Category",
            "",
            "| Category | Count | Percentage |",
            "|----------|-------|------------|",
        ])
        
        total = test_plan.total_tests
        for cat, count in test_plan.by_category.items():
            pct = (count / total * 100) if total > 0 else 0
            lines.append(f"| {cat} | {count} | {pct:.0f}% |")
            
        lines.extend([
            "",
            "---",
            "",
            "## Detailed Test Cases",
            "",
        ])
        
        # Group by category
        by_cat = {}
        for tc in test_plan.test_cases:
            cat = tc.category.value
            if cat not in by_cat:
                by_cat[cat] = []
            by_cat[cat].append(tc)
            
        for cat in ["Security", "Functional", "Input Validation", "UI/UX", "Edge Cases"]:
            if cat in by_cat:
                lines.append(f"### {cat} Tests ({len(by_cat[cat])})")
                lines.append("")
                
                for tc in by_cat[cat]:
                    risk_emoji = {"Critical": "ðŸ”´", "High": "ðŸŸ ", "Medium": "ðŸŸ¡", "Low": "ðŸŸ¢"}.get(tc.risk_level.value, "âšª")
                    lines.append(f"#### {tc.id}: {tc.title}")
                    lines.append(f"**Risk:** {risk_emoji} {tc.risk_level.value}")
                    lines.append("")
                    
                    if tc.preconditions:
                        lines.append("**Preconditions:**")
                        for pre in tc.preconditions:
                            lines.append(f"- {pre}")
                        lines.append("")
                        
                    lines.append("**Steps:**")
                    for i, step in enumerate(tc.steps, 1):
                        lines.append(f"{i}. {step}")
                    lines.append("")
                    
                    lines.append(f"**Expected Result:** {tc.expected_result}")
                    lines.append("")
                    lines.append(f"*{tc.source_citation}*")
                    lines.append("")
                    lines.append("---")
                    lines.append("")
                    
        # Sources
        lines.extend([
            "## Knowledge Sources Referenced",
            "",
        ])
        
        for cite in sorted(set(test_plan.all_citations)):
            lines.append(f"- {cite}")
            
        lines.extend([
            "",
            "---",
            "",
            "*Report generated by TestAI Agent - Cognitive QA System*",
            f"*Version 1.0 | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
        ])
        
        return '\n'.join(lines)
    
    @classmethod
    def to_html(cls, test_plan, executive_summary: ExecutiveSummary) -> str:
        """Generate an HTML report suitable for email."""
        
        # Convert markdown to simple HTML
        md = cls.to_markdown(test_plan, executive_summary)
        
        html = """<!DOCTYPE html>
<html>
<head>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 800px; margin: 40px auto; padding: 20px; }
        h1 { color: #1a1a2e; border-bottom: 2px solid #16213e; padding-bottom: 10px; }
        h2 { color: #16213e; margin-top: 30px; }
        h3 { color: #0f3460; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background-color: #16213e; color: white; }
        tr:nth-child(even) { background-color: #f2f2f2; }
        .critical { color: #dc3545; font-weight: bold; }
        .high { color: #fd7e14; font-weight: bold; }
        .medium { color: #ffc107; }
        .low { color: #28a745; }
        code { background-color: #f4f4f4; padding: 2px 6px; border-radius: 3px; }
        blockquote { border-left: 4px solid #16213e; padding-left: 20px; margin: 20px 0; color: #666; }
    </style>
</head>
<body>
"""
        
        # Simple markdown to HTML conversion
        import re
        
        # Convert markdown elements
        md = re.sub(r'^# (.+)$', r'<h1>\1</h1>', md, flags=re.MULTILINE)
        md = re.sub(r'^## (.+)$', r'<h2>\1</h2>', md, flags=re.MULTILINE)
        md = re.sub(r'^### (.+)$', r'<h3>\1</h3>', md, flags=re.MULTILINE)
        md = re.sub(r'^#### (.+)$', r'<h4>\1</h4>', md, flags=re.MULTILINE)
        md = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', md)
        md = re.sub(r'\*(.+?)\*', r'<em>\1</em>', md)
        md = re.sub(r'^- (.+)$', r'<li>\1</li>', md, flags=re.MULTILINE)
        md = re.sub(r'^(\d+)\. (.+)$', r'<li>\2</li>', md, flags=re.MULTILINE)
        md = re.sub(r'^---$', r'<hr>', md, flags=re.MULTILINE)
        
        # Convert tables (simplified)
        lines = md.split('\n')
        in_table = False
        result_lines = []
        
        for line in lines:
            if '|' in line and not line.strip().startswith('|---'):
                if not in_table:
                    result_lines.append('<table>')
                    in_table = True
                cells = [c.strip() for c in line.split('|')[1:-1]]
                if result_lines[-1] == '<table>':
                    row = '<tr>' + ''.join(f'<th>{c}</th>' for c in cells) + '</tr>'
                else:
                    row = '<tr>' + ''.join(f'<td>{c}</td>' for c in cells) + '</tr>'
                result_lines.append(row)
            elif line.strip().startswith('|---'):
                continue
            else:
                if in_table:
                    result_lines.append('</table>')
                    in_table = False
                result_lines.append(line)
                
        if in_table:
            result_lines.append('</table>')
            
        html += '\n'.join(result_lines)
        html += "\n</body>\n</html>"
        
        return html
    
    @classmethod  
    def to_plain_text(cls, test_plan, executive_summary: ExecutiveSummary) -> str:
        """Generate a plain text report for terminal display."""
        
        width = 70
        sep = "=" * width
        thin_sep = "-" * width
        
        lines = [
            sep,
            "QA TEST PLAN REPORT".center(width),
            sep,
            "",
            f"Feature: {test_plan.feature}",
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"By: TestAI Agent (Senior QA Consultant)",
            "",
            thin_sep,
            "EXECUTIVE SUMMARY".center(width),
            thin_sep,
            "",
            f"Overall Risk Level:     {executive_summary.overall_risk}",
            f"Total Test Cases:       {executive_summary.test_count}",
            f"Critical Priority:      {executive_summary.critical_tests}",
            f"High Priority:          {executive_summary.high_tests}",
            f"Estimated Effort:       {executive_summary.estimated_effort}",
            f"Confidence Level:       {executive_summary.confidence_level}",
            "",
            "Key Findings:",
        ]
        
        for finding in executive_summary.key_findings:
            lines.append(f"  * {finding}")
            
        lines.extend([
            "",
            "Recommendations:",
        ])
        
        for i, rec in enumerate(executive_summary.recommendations, 1):
            lines.append(f"  {i}. {rec}")
            
        lines.extend([
            "",
            thin_sep,
            "TEST COVERAGE".center(width),
            thin_sep,
            "",
        ])
        
        for cat, count in test_plan.by_category.items():
            pct = (count / test_plan.total_tests * 100) if test_plan.total_tests > 0 else 0
            bar_len = int(pct / 5)
            bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
            lines.append(f"  {cat:20s} {bar} {count:3d} ({pct:.0f}%)")
            
        lines.extend([
            "",
            sep,
            f"Full report: {test_plan.total_tests} test cases generated",
            "Run 'export' to save detailed report to file",
            sep,
        ])
        
        return '\n'.join(lines)
